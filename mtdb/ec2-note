Running on EC2 VM

Set hostname
	Dot in the hostname doesn't work, i.e., hostname0=ec2-m3.xlarge.s0
	Excute both for export ec2-s0-m3-xlarge ec2-c0-m3-xlarge

	export hostname0=ec2-s-i2.xlarge \

	export hostname0=ec2-s-c3.2xlarge \
	&& sudo sed -i 's/localhost$/localhost '$hostname0'/g' /etc/hosts \
	&& sudo bash -c 'echo '$hostname0' > /etc/hostname' \
	&& sudo hostname --file /etc/hostname

	exit and login back


Install packages, vmtouch,
, one-time synchronization of clocks both on server and client
, setup repositories and dev envs

	(will be prompted for an Oracle binary code license)
	(will be prompted for if you trust the server)

	sudo add-apt-repository -y ppa:webupd8team/java \
	&& sudo apt-get update \
	&& sudo apt-get install oracle-java8-installer git ctags ant htop tree maven \
	gnuplot-nox ntp ioping realpath make gcc cmake g++ \
	libboost-dev libboost-system-dev libboost-timer-dev \
	sysstat -y \
	&& sudo apt-get autoremove -y vim-tiny \
	&& mkdir -p ~/work \
	&& cd ~/work \
	&& git clone https://github.com/hoytech/vmtouch.git \
	&& cd vmtouch \
	&& make -j \
	&& sudo make install \
	&& sudo service ntp stop \
	&& sudo ntpdate -bv 0.ubuntu.pool.ntp.org \
	&& sudo service ntp start \
	&& cd ~/work \
	&& git clone git@github.com:hobinyoon/linux-home.git \
	&& cd linux-home \
	&& ./setup-linux.sh

	exit and login back


Set firewall rules on Server. Allow client machine to connect to server machine
on AWS console
	Allow inbound TCP 9042 10.152.33.227/32


Set server address on client machine
	On server:
		vi ~/.bashrc
			export CASSANDRA_CLIENT_ADDR=54.152.9.237

	On client:
		vi ~/.bashrc
			export CASSANDRA_SERVER_ADDR=54.197.84.25

	exit and login back to make them take effect


Prepare a local SSD volume and an EBS volume
	lsblk
		NAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
		xvda    202:0    0     8G  0 disk
		└─xvda1 202:1    0     8G  0 part /
		xvdb    202:16   0  15.3G  0 disk /mnt
		xvdc    202:32   0  15.3G  0 disk
		xvdd    202:48   0     8G  0 disk

	sudo mkfs.ext4 -m 0 /dev/xvdc
	(xvdb is already formatted)

	sudo vi /etc/fstab
		/dev/xvdb /mnt/local-ssd  auto  defaults,nobootwait,comment=cloudconfig 0 2
		/dev/xvdd /mnt/ebs-mag  auto  defaults,nobootwait,comment=cloudconfig 0 2
		(EBS-SSD-GP2 is already mounted at /)

	On the server machine:
		sudo umount /mnt \
		&& sudo mkdir -p /mnt/local-ssd \
		&& sudo mkdir -p /mnt/ebs-mag \
		&& sudo mount /mnt/local-ssd \
		&& sudo mount /mnt/ebs-mag \
		&& sudo chown -R ubuntu /mnt/local-ssd \
		&& sudo chown -R ubuntu /mnt/ebs-mag \
		&& mkdir ~/cass-data-vol \
		&& sudo ln -s ~/cass-data-vol /mnt/ebs-ssd-gp2

	On the machine with local-ssd and ebs-ssd-gp2:
		sudo umount /mnt \
		&& sudo mkdir -p /mnt/local-ssd \
		&& sudo mount /mnt/local-ssd \
		&& sudo chown -R ubuntu /mnt/local-ssd \
		&& mkdir /mnt/local-ssd/cass-data \
		&& mkdir ~/cass-data-vol \
		&& sudo ln -s ~/cass-data-vol /mnt/ebs-ssd-gp2 \
		&& mkdir /mnt/ebs-ssd-gp2/cass-data


Setup Cassandra directory both on server and client. It goes to the root volume. It's okay.
	cd ~/work \
	&& git clone git@github.com:hobinyoon/apache-cassandra-2.2.3-src.git \
	&& ln -s ~/work/apache-cassandra-2.2.3-src ~/work/cassandra


Run Mutants server
	Setup cold storage
		sudo mkdir -p /mnt/ebs-ssd-gp2/mtdb-cold \
		&& sudo mkdir -p /mnt/ebs-mag/mtdb-cold \
		&& sudo ln -s /mnt/ebs-ssd-gp2 /mnt/cold-storage \
		&& sudo chown -R ubuntu /mnt/ebs-ssd-gp2 \
		&& sudo chown -R ubuntu /mnt/cold-storage \
		&& sudo chown -R ubuntu /mnt/cold-storage/mtdb-cold

		On a machine without ebs-mag
			sudo mkdir -p /mnt/ebs-ssd-gp2/mtdb-cold \
			&& sudo ln -s /mnt/ebs-ssd-gp2 /mnt/cold-storage \
			&& sudo chown -R ubuntu /mnt/ebs-ssd-gp2 \
			&& sudo chown -R ubuntu /mnt/cold-storage \
			&& sudo chown -R ubuntu /mnt/cold-storage/mtdb-cold

	Change data directory to ebs-ssd (or to local-ssd)
		&& ln -s /mnt/ebs-ssd-gp2/cass-data ~/work/cassandra/data

	Run server after dropping page cache
		screen

		sudo -- sh -c 'echo 1 > /proc/sys/vm/drop_caches' \
		&& cdcass \
		&& time ant \
		&& rm -rf ~/work/cassandra/data/* \
		&& (killall sar > /dev/null 2>&1 || true) && ((sar 1 > ~/work/cassandra/mtdb/logs/sar/sar-`date +'%y%m%d-%H%M%S'`) &) \
		&& bin/cassandra -f | grep --color -E '^|MTDB:'

	Watch free memory
	  watch -n 0.5 "free -mt"

	Watch sstables
	  watchsstables

	Pressure memory. It can be launched in the background, and monitored by htop.
		cd ~/work/cassandra/mtdb/tools/pressure-memory \
		&& mkdir -p .build \
		&& cd .build \
		&& cmake .. \
		&& make -j && ./pressure-memory


Run loadgen client, preferrably on a different machine
	It read the env var CASSANDRA_SERVER_ADDR.

	cd ~/work/cassandra/mtdb/loadgen \
	&& ./create-db.sh \
	&& ./loadgen

	Monitor it's not running behind.


Get loadgen client log to server machine. Better do this on the server node,
which is likely to have bigger log files. Process the experiment.
	rsync -av $CASSANDRA_CLIENT_ADDR:work/cassandra/mtdb/logs/loadgen ~/work/cassandra/mtdb/logs \
	&& cd ~/work/cassandra/mtdb/process-log/calc-cost-latency-plot-tablet-timeline \
	&& (\rm *.pdf || true) \
	&& ./plot-cost-latency-tablet-timelines.py \
	&& scp -P 20022 *.pdf hobin@localhost:


Copy logs to mts7
	rsync -av ubuntu@54.162.89.211:work/cassandra/mtdb/logs ~/work/cassandra/mtdb/


NFS
	server
		sudo vi /etc/exports
			/nfs-export       54.205.183.58/32(rw,fsid=0,insecure,no_subtree_check,async)

		sudo apt-get install nfs-kernel-server -y \
		&& sudo mkdir -p /nfs-export \
		&& sudo chown -R ubuntu /nfs-export \
		&& sudo service nfs-kernel-server restart

	client
		sudo vi /etc/fstab
			54.165.74.184:/   /mnt/nfs-ebs-ssd   nfs    auto  0  0

		sudo apt-get install nfs-common -y \
		&& sudo mkdir /mnt/nfs-ebs-ssd \
		&& sudo mount /mnt/nfs-ebs-ssd
