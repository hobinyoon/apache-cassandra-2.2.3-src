Running on EC2

Launching spot instances
	(Use web interface for now)

	Delete some machine finger prints in ~/.ssh/known_hosts to avoid ssh getting
	confused.

	aws ec2 request-spot-instances --dry-run --spot-price 1 --type c3.2xlarge --availability-zone-group us-east-1

	Set firewall rules on Server. Allow client machine to connect to server
	machine on AWS console
		Allow inbound TCP 9042 10.152.33.227/32

	AWS command line interface
		https://aws.amazon.com/cli/

		sudo pip install --ignore-installed awscli

		aws configure
		aws ec2 describe-instances


Get hostname lists. Set hostname and edit .bashrc. All automated.
	create-hostname-lists.py \
	&& set-hostname-edit-bashrc.py

		On server:
			echo 'export CASSANDRA_CLIENT_ADDR=54.88.197.238' >> ~/.bashrc
		On client:
			echo 'export CASSANDRA_SERVER_ADDR=23.22.13.183'   >> ~/.bashrc


---- From here, things are automated by AppleScript ----------------------------

Install packages, vmtouch
, one-time synchronization of clocks both on server and client
, setup repositories and dev envs

	(will be prompted for an Oracle binary code license)
	(will be prompted for if you trust the server)

	rsync from an existing machine, when the ubuntu servers are slow.
		(rsync -av ubuntu@54.204.181.71:/var/cache/apt/archives ~/ || true) \
		&& (sudo cp ~/archives/* /var/cache/apt/archives/ || true) \

	sudo add-apt-repository -y ppa:webupd8team/java \
	&& sudo apt-get update \
	&& sudo apt-get install oracle-java8-installer git ctags ant htop tree maven \
	gnuplot-nox ntp ioping realpath make gcc cmake g++ \
	libboost-dev libboost-system-dev libboost-timer-dev \
	collectl -y \
	&& sudo apt-get autoremove -y vim-tiny \
	&& mkdir -p ~/work \
	&& cd ~/work \
	&& git clone https://github.com/hoytech/vmtouch.git \
	&& cd vmtouch \
	&& make -j \
	&& sudo make install \
	&& sudo service ntp stop \
	&& sudo ntpdate -bv 0.ubuntu.pool.ntp.org \
	&& sudo service ntp start \
	&& cd ~/work \
	&& git clone git@github.com:hobinyoon/linux-home.git \
	&& cd linux-home \
	&& ./setup-linux.sh


Setup Cassandra directory both on server and client. It goes to the root
volume. It's okay. Can be done in the background to save time.

	On server
		screen

		cd ~/work \
		&& git clone git@github.com:hobinyoon/apache-cassandra-2.2.3-src.git \
		&& ln -s ~/work/apache-cassandra-2.2.3-src ~/work/cassandra \
		&& cdcass \
		&& time ant

	On client
		screen

		cd ~/work \
		&& git clone git@github.com:hobinyoon/apache-cassandra-2.2.3-src.git \
		&& ln -s ~/work/apache-cassandra-2.2.3-src ~/work/cassandra \
		&& cd ~/work/cassandra/mtdb/loadgen \
		&& ./loadgen


Prepare a local SSD volume and an EBS volume
	lsblk
		NAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
		xvda    202:0    0     8G  0 disk
		└─xvda1 202:1    0     8G  0 part /
		xvdb    202:16   0  15.3G  0 disk /mnt
		xvdc    202:32   0  15.3G  0 disk
		xvdd    202:48   0     8G  0 disk

	sudo mkfs.ext4 -m 0 /dev/xvdd
	(xvdb is already formatted)

	sudo vi /etc/fstab
		/dev/xvdb /mnt/local-ssd  auto  defaults,nobootwait,comment=cloudconfig 0 2
		/dev/xvdf /mnt/ebs-mag  auto  defaults,nobootwait,comment=cloudconfig 0 2
		(EBS-SSD-GP2 is already mounted at /)

	On the machine with local-ssd and ebs-ssd-gp2:
		sudo umount /mnt \
		&& sudo mkdir -p /mnt/local-ssd \
		&& sudo mount /mnt/local-ssd \
		&& sudo chown -R ubuntu /mnt/local-ssd \
		&& mkdir /mnt/local-ssd/cass-data \
		&& mkdir ~/cass-data-vol \
		&& sudo ln -s ~/cass-data-vol /mnt/ebs-ssd-gp2 \
		&& mkdir /mnt/ebs-ssd-gp2/cass-data

	Add EBS mag
		sudo mkdir -p /mnt/ebs-mag \
		&& sudo mount /mnt/ebs-mag \
		&& sudo mkdir /mnt/ebs-mag/cass-data \
		&& sudo chown -R ubuntu /mnt/ebs-mag \
		&& sudo chown -R ubuntu /mnt/ebs-mag/cass-data


Run Mutants server
	Setup cold storage
		sudo mkdir -p /mnt/ebs-ssd-gp2/mtdb-cold \
		&& (sudo mkdir -p /mnt/ebs-mag/mtdb-cold || true) \
		&& sudo ln -s /mnt/ebs-ssd-gp2 /mnt/cold-storage \
		&& sudo chown -R ubuntu /mnt/ebs-ssd-gp2 \
		&& sudo chown -R ubuntu /mnt/cold-storage \
		&& sudo chown -R ubuntu /mnt/cold-storage/mtdb-cold \
		&& mkdir -p ~/work/cassandra/mtdb/logs/collectl

	Setup data directory
		ln -s /mnt/local-ssd/cass-data ~/work/cassandra/data

	The above 4 steps at once. TODO: better make it as a script that can be run inside the VM.
		sudo umount /mnt \
		&& sudo mkdir -p /mnt/local-ssd \
		&& sudo mount /mnt/local-ssd \
		&& sudo chown -R ubuntu /mnt/local-ssd \
		&& mkdir /mnt/local-ssd/cass-data \
		&& mkdir ~/cass-data-vol \
		&& sudo ln -s ~/cass-data-vol /mnt/ebs-ssd-gp2 \
		&& mkdir /mnt/ebs-ssd-gp2/cass-data \
		&& sudo mkdir -p /mnt/ebs-mag \
		&& sudo mount /mnt/ebs-mag \
		&& sudo mkdir /mnt/ebs-mag/cass-data \
		&& sudo chown -R ubuntu /mnt/ebs-mag \
		&& sudo chown -R ubuntu /mnt/ebs-mag/cass-data \
		&& sudo mkdir -p /mnt/ebs-ssd-gp2/mtdb-cold \
		&& (sudo mkdir -p /mnt/ebs-mag/mtdb-cold || true) \
		&& sudo ln -s /mnt/ebs-mag /mnt/cold-storage \
		&& sudo chown -R ubuntu /mnt/ebs-ssd-gp2 \
		&& sudo chown -R ubuntu /mnt/cold-storage \
		&& sudo chown -R ubuntu /mnt/cold-storage/mtdb-cold \
		&& mkdir -p ~/work/cassandra/mtdb/logs/collectl \
		&& ln -s /mnt/local-ssd/cass-data ~/work/cassandra/data

	Run server after dropping page cache
		screen

		sudo -- sh -c 'echo 1 > /proc/sys/vm/drop_caches' \
		&& cdcass \
		&& time ant \
		&& rm -rf ~/work/cassandra/data/* \
		&& (killall mon-num-cass-threads.sh >/dev/null 2>&1 || true) \
		&& (~/work/cassandra/mtdb/tools/mon-num-cass-threads.sh &) \
		&& (killall collectl >/dev/null 2>&1 || true) \
		&& ((collectl -i 1 -sCDN -oTm > ~/work/cassandra/mtdb/logs/collectl/collectl-`date +'%y%m%d-%H%M%S'` 2>/dev/null) &) \
		&& bin/cassandra -f | grep --color -E '^|MTDB:'

	Watch free memory
	  watch -n 0.5 "free -mt"

	Pressure memory. It can be launched in the background, and monitored by htop.
	After Cassandra is ready.
	Watch sstables

		cd ~/work/cassandra/mtdb/tools/pressure-memory \
		&& mkdir -p .build \
		&& cd .build \
		&& cmake .. \
		&& make -j && (./pressure-memory &) \
		&& watchsstables

	Save screen layout
		Ctrl-a :layout save default


Run loadgen client on client machine
	It read the env var CASSANDRA_SERVER_ADDR.

	cd ~/work/cassandra/mtdb/loadgen \
	&& ./create-db.sh \
	&& ./loadgen

	Monitor it's not running behind.


Get loadgen client log to server machine. Better do this on the server node,
which is likely to have bigger log files. Process the experiment.

	(killall pressure-memory > /dev/null 2>&1 || true) \
	&& rsync -ave "ssh -o StrictHostKeyChecking=no" $CASSANDRA_CLIENT_ADDR:work/cassandra/mtdb/logs/loadgen ~/work/cassandra/mtdb/logs \
	&& (killall mon-num-cass-threads.sh >/dev/null 2>&1 || true) \
	&& cd ~/work/cassandra/mtdb/process-log/calc-cost-latency-plot-tablet-timeline \
	&& (\rm *.pdf || true) \
	&& ./plot-cost-latency-tablet-timelines.py \
	&& du -hs ~/work/cassandra/data/ \
	&& scp -P 20022 *.pdf hobin@localhost:

---- To here ------------------------------------------------------------------

Check Mutants data size
	check-mustants-data-size.py


Copy logs to current machine, like mt-s7
	copy-ec2-logs.py
